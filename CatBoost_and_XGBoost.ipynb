{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (1.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: six in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How to find optimal parameters for CatBoost using GridSearchCV for Classification*\n",
      "0:\tlearn: 0.5183343\ttotal: 15.4ms\tremaining: 911ms\n",
      "1:\tlearn: 0.3739756\ttotal: 29.2ms\tremaining: 847ms\n",
      "2:\tlearn: 0.2292519\ttotal: 43ms\tremaining: 817ms\n",
      "3:\tlearn: 0.1608938\ttotal: 56.2ms\tremaining: 786ms\n",
      "4:\tlearn: 0.1255120\ttotal: 71.3ms\tremaining: 784ms\n",
      "5:\tlearn: 0.1095145\ttotal: 85.4ms\tremaining: 768ms\n",
      "6:\tlearn: 0.0878307\ttotal: 99.1ms\tremaining: 751ms\n",
      "7:\tlearn: 0.0722121\ttotal: 113ms\tremaining: 737ms\n",
      "8:\tlearn: 0.0644426\ttotal: 128ms\tremaining: 724ms\n",
      "9:\tlearn: 0.0560055\ttotal: 141ms\tremaining: 705ms\n",
      "10:\tlearn: 0.0493450\ttotal: 148ms\tremaining: 658ms\n",
      "11:\tlearn: 0.0452479\ttotal: 161ms\tremaining: 644ms\n",
      "12:\tlearn: 0.0412977\ttotal: 176ms\tremaining: 635ms\n",
      "13:\tlearn: 0.0375822\ttotal: 188ms\tremaining: 618ms\n",
      "14:\tlearn: 0.0356573\ttotal: 201ms\tremaining: 604ms\n",
      "15:\tlearn: 0.0330101\ttotal: 215ms\tremaining: 591ms\n",
      "16:\tlearn: 0.0312251\ttotal: 233ms\tremaining: 589ms\n",
      "17:\tlearn: 0.0285760\ttotal: 247ms\tremaining: 577ms\n",
      "18:\tlearn: 0.0272841\ttotal: 260ms\tremaining: 561ms\n",
      "19:\tlearn: 0.0259093\ttotal: 274ms\tremaining: 547ms\n",
      "20:\tlearn: 0.0243268\ttotal: 286ms\tremaining: 532ms\n",
      "21:\tlearn: 0.0232261\ttotal: 300ms\tremaining: 518ms\n",
      "22:\tlearn: 0.0221004\ttotal: 312ms\tremaining: 502ms\n",
      "23:\tlearn: 0.0207098\ttotal: 326ms\tremaining: 489ms\n",
      "24:\tlearn: 0.0196363\ttotal: 339ms\tremaining: 474ms\n",
      "25:\tlearn: 0.0187420\ttotal: 352ms\tremaining: 460ms\n",
      "26:\tlearn: 0.0179175\ttotal: 365ms\tremaining: 447ms\n",
      "27:\tlearn: 0.0172019\ttotal: 379ms\tremaining: 433ms\n",
      "28:\tlearn: 0.0163770\ttotal: 393ms\tremaining: 420ms\n",
      "29:\tlearn: 0.0158406\ttotal: 407ms\tremaining: 407ms\n",
      "30:\tlearn: 0.0152973\ttotal: 423ms\tremaining: 396ms\n",
      "31:\tlearn: 0.0148790\ttotal: 437ms\tremaining: 382ms\n",
      "32:\tlearn: 0.0141385\ttotal: 452ms\tremaining: 370ms\n",
      "33:\tlearn: 0.0137297\ttotal: 467ms\tremaining: 357ms\n",
      "34:\tlearn: 0.0131917\ttotal: 482ms\tremaining: 344ms\n",
      "35:\tlearn: 0.0127484\ttotal: 497ms\tremaining: 331ms\n",
      "36:\tlearn: 0.0124373\ttotal: 513ms\tremaining: 319ms\n",
      "37:\tlearn: 0.0121476\ttotal: 527ms\tremaining: 305ms\n",
      "38:\tlearn: 0.0118350\ttotal: 541ms\tremaining: 291ms\n",
      "39:\tlearn: 0.0115538\ttotal: 554ms\tremaining: 277ms\n",
      "40:\tlearn: 0.0113221\ttotal: 569ms\tremaining: 264ms\n",
      "41:\tlearn: 0.0110160\ttotal: 582ms\tremaining: 249ms\n",
      "42:\tlearn: 0.0106752\ttotal: 596ms\tremaining: 235ms\n",
      "43:\tlearn: 0.0104414\ttotal: 611ms\tremaining: 222ms\n",
      "44:\tlearn: 0.0102480\ttotal: 623ms\tremaining: 208ms\n",
      "45:\tlearn: 0.0098818\ttotal: 637ms\tremaining: 194ms\n",
      "46:\tlearn: 0.0096739\ttotal: 651ms\tremaining: 180ms\n",
      "47:\tlearn: 0.0094550\ttotal: 666ms\tremaining: 166ms\n",
      "48:\tlearn: 0.0093153\ttotal: 679ms\tremaining: 152ms\n",
      "49:\tlearn: 0.0091427\ttotal: 693ms\tremaining: 139ms\n",
      "50:\tlearn: 0.0089372\ttotal: 706ms\tremaining: 125ms\n",
      "51:\tlearn: 0.0087960\ttotal: 719ms\tremaining: 111ms\n",
      "52:\tlearn: 0.0086617\ttotal: 732ms\tremaining: 96.7ms\n",
      "53:\tlearn: 0.0085187\ttotal: 746ms\tremaining: 82.9ms\n",
      "54:\tlearn: 0.0083586\ttotal: 760ms\tremaining: 69.1ms\n",
      "55:\tlearn: 0.0082209\ttotal: 772ms\tremaining: 55.2ms\n",
      "56:\tlearn: 0.0081222\ttotal: 786ms\tremaining: 41.4ms\n",
      "57:\tlearn: 0.0079355\ttotal: 800ms\tremaining: 27.6ms\n",
      "58:\tlearn: 0.0077307\ttotal: 815ms\tremaining: 13.8ms\n",
      "59:\tlearn: 0.0076295\ttotal: 830ms\tremaining: 0us\n",
      "\n",
      "========================================================\n",
      " Results from Random Search \n",
      "========================================================\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " <catboost.core.CatBoostClassifier object at 0x0000027121C01400>\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.977498869289914\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'depth': 8, 'iterations': 60, 'learning_rate': 0.9700798908478415}\n",
      "\n",
      " ========================================================\n"
     ]
    }
   ],
   "source": [
    "def Snippet_200(): \n",
    "    print()\n",
    "    print(format('How to find optimal parameters for CatBoost using GridSearchCV for Classification','*^82'))   \n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # load libraries\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import uniform as sp_randFloat\n",
    "    from scipy.stats import randint as sp_randInt    \n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    #load the iris datasets\n",
    "    dataset = datasets.load_wine()\n",
    "    #(11/28 - ASSIGN STUDENT DATA TO THE VARIABLES)X = dataset.data; y = dataset.target\n",
    "    #X, y = get_dataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    model = CatBoostClassifier()\n",
    "    parameters = {'depth'         : sp_randInt(4, 10),\n",
    "                  'learning_rate' : sp_randFloat(),\n",
    "                  'iterations'    : sp_randInt(10, 100)\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 2, n_iter = 10, n_jobs=-1)\n",
    "    randm.fit(X_train, y_train)\n",
    "\n",
    "    # Results from Random Search\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\" Results from Random Search \" )\n",
    "    print(\"========================================================\")    \n",
    "    print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "          randm.best_estimator_)\n",
    "    print(\"\\n The best score across ALL searched params:\\n\",\n",
    "          randm.best_score_)\n",
    "    print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          randm.best_params_)\n",
    "    print(\"\\n ========================================================\")\n",
    "    \n",
    "Snippet_200()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.1-py3-none-win_amd64.whl (89.1 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sbondu\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
      "              predictor='auto', ...)\n",
      "\n",
      "XGBClassifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      0.73      0.85        15\n",
      "     class_1       0.89      0.94      0.91        17\n",
      "     class_2       0.81      1.00      0.90        13\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.90      0.89      0.89        45\n",
      "weighted avg       0.90      0.89      0.89        45\n",
      "\n",
      "\n",
      "[[11  2  2]\n",
      " [ 0 16  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the wine datasets\n",
    "dataset = datasets.load_wine()\n",
    "#(11/28 - ASSIGN STUDENT DATA TO THE VARIABLES) X = dataset.data; y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(X.shape); print(model)\n",
    "\n",
    "# make predictions\n",
    "expected_y = y_test\n",
    "predicted_y = model.predict (X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(); print('XGBClassifier: ')\n",
    "print(); print(metrics.classification_report(expected_y, predicted_y,target_names=dataset.target_names))\n",
    "print(); print (metrics.confusion_matrix(expected_y, predicted_y))\n",
    "#plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "#plt.show()\n",
    "#plt.barh(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "#plt.show()\n",
    "#plot_importance(model); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
